\begin{thebibliography}{1}

\bibitem{adv}
Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, and Qian Wang.
\newblock Recent advances in adversarial training for adversarial robustness,
  2021.

\bibitem{gan}
Ian~J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David
  Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks, 2014.

\bibitem{advExamples}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples, 2014.

\bibitem{ytLatentVector}
Arxiv Insights.
\newblock Editing faces using artificial intelligence.

\bibitem{gat}
Hyeungill Lee, Sungyeob Han, and Jungwoo Lee.
\newblock Generative adversarial trainer: Defense to adversarial perturbations
  with gan, 2017.

\bibitem{latentVector}
Zachary~C. Lipton and Subarna Tripathi.
\newblock Precise recovery of latent vectors from generative adversarial
  networks, 2017.

\bibitem{deepFool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: A simple and accurate method to fool deep neural networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem{mixup2}
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas,
  Aaron Courville, David Lopez-Paz, and Yoshua Bengio.
\newblock Manifold mixup: Better representations by interpolating hidden
  states, 2018.

\bibitem{mixup1}
Hongyi Zhang, Moustapha Cisse, Yann~N. Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization, 2017.

\end{thebibliography}
